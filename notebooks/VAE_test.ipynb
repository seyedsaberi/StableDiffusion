{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d69832bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ad8251",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('../')\n",
    "epoch_num = 20\n",
    "batch_size = 128\n",
    "lr = 1e-4\n",
    "sigma = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e041963",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sd.datasets import CelebADataset\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "image_directory = '/kaggle/input/celeba-dataset/img_align_celeba/img_align_celeba/'\n",
    "full_dataset = CelebADataset(image_directory)\n",
    "train_size = int(len(full_dataset) * 0.8)\n",
    "val_size = len(full_dataset) - train_size\n",
    "\n",
    "train_dataset, val_dataset = random_split(\n",
    "    full_dataset,\n",
    "    [train_size, val_size],\n",
    "    generator=torch.Generator().manual_seed(42)\n",
    ")\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7dc66e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sd.train import VAE_Trainer\n",
    "\n",
    "trainer = VAE_Trainer(lr, sigma)\n",
    "trainer.train(train_loader, val_loader, epoch_num)\n",
    "encoder = trainer.encoder\n",
    "decoder = trainer.decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61091d04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sd.dataseta import show_images\n",
    "batch = next(iter(val_loader))\n",
    "x = batch['image'][:5].to(trainer.device)\n",
    "with torch.no_grad():\n",
    "    n, c, h, w = x.shape\n",
    "    noise = torch.randn(n, 4, h//8, w//8)\n",
    "    z, _, _ = trainer.encoder(x, noise)\n",
    "    x_hat = trainer.decoder(z)\n",
    "show_images(x, 'Original Images')\n",
    "show_images(x_hat, 'Re-generated Images')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e7f618",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    z = torch.randn(n, 5 , h//8, w//8)\n",
    "    generated_images = trainer.decoder(z)\n",
    "show_images(genrated_images, \"Generated_images\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
